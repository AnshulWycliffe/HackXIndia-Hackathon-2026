# ğŸŒ¾ Aksara Farming Advisor

Aksara Farming Advisor is an **AI-powered farming assistant** built using **Flask**, **llama-cpp-python**, and a modern streaming chat UI.  
It leverages the **Aksara v1 GGUF LLM** to provide **structured, agriculture-focused responses** for farmers and agriculture enthusiasts.
- Model URL: [huggingFace/cropinailab/aksara_v1](https://huggingface.co/cropinailab/aksara_v1)
- Github Repo: [github/Cropin-AILab/aksara](https://github.com/Cropin-AILab/aksara)

# Description by the CropinAILab
aká¹£ara, is a Micro Language Model ((Âµ-LM)) and is a fine-tuned version of the Mistral-7B-Instruct-v0.2 model. The model is fine-tuned using proprietary and open-source agricultural data. The data is specific to five countries in the global south: India, Bangladesh, Sri Lanka, Pakistan and Nepal, and covers nine of the major crops of the region like paddy/rice, wheat, maize, barley, sorghum, cotton, sugarcane, millets, soybean. It was compressed by using the QLoRA technique that compresses the model from 16-bit to 4-bit precision leading to a 60% reduction in the model size! It gives about 40% more relevant ROUGE score than GPT-4 Turbo on randomly selected test datasets.

The knowledge domain of the model is specific to the agricultural best practices, including climate-smart agricultural practices (CSA) and regenerative agricultural practices (RA) for the above-mentioned focus countries and crops. More geographies and crops will be added later. The model is trained on a database containing information from seed sowing to harvesting, covering every phenological stage of the crop growth cycle and different aspects like crop health management, soil management, disease control, and others. The end-to-end pipeline incorporates various aspects of Responsible AI (RAI), like considering local features and preventing harmful content or misinformation.

The following hyperparameters were used during training:

learning_rate: 2e-4 train_batch_size: 4 eval_batch_size: 4 optimizer: paged_adam_32bit lr_scheduler_type: cosine num_epochs: 1 lora_r: 32 weight_decay: 0.001 For full details of this model please read our release blog post here. The technical details for the background, fine-tuning and reproducibility will be shared as a pre-print on arxiv very soon. The model can be inferenced on our Huggingface Space aksara spaces For framework versions, please refer to the requirements.txt file.

Developed by: Cropin AI Lab Contact: ailabs@cropin.com

Limitations The knowledge of aká¹£ara is limited to the specific region and crops. We are looking forward to engage with the community on ways to make it better on the model, data, pipeline and "Responsible AI".

Disclaimer Beta Test version #1.0 - aksara is your agricultural AI advisor. Expect inaccuracies. Weâ€™re in active development stage to constantly learn & improve.

Blog: https://www.cropin.com/blogs/introducing-aksara-a-digital-agronomist First Version release: April 16, 2024.

Demo: https://huggingface.co/spaces/cropinailab/aksara Model Card: https://huggingface.co/cropinailab/aksara_v1

---

## ğŸš€ Features

- ğŸ¤– **Local LLM (GGUF)** using `llama-cpp-python`
- ğŸŒ± **Strict agriculture-only responses**
- ğŸ§  **Strong system prompt enforcement**
- ğŸ“¡ **Real-time streaming responses**
- ğŸŒ **Modern chat UI (HTML, CSS, JavaScript)**
- ğŸ” **CORS enabled API**
- ğŸŒ **Ngrok support for public access**
- ğŸ‡®ğŸ‡³ **English & Hindi (Devanagari) support**
- âš¡ GPU acceleration support

---

## ğŸ—‚ï¸ Project Structure

```
aksara-farming-advisor/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ test_aksara_v1.ipynb
â”œâ”€â”€ Aksara Farming AI Test Questions.docx
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â””â”€â”€ README.md
```

---

## ğŸ§  Model Details

- **Model:** `aksara_v1.Q4_K_M.gguf`
- **Format:** GGUF (4-bit quantized)
- **Source:** Hugging Face â€“ `cropinailab/aksara_v1_GGUF`
- **Context Length:** 4096 tokens
- **GPU Support:** Enabled (`n_gpu_layers = -1`)

---

## âš™ï¸ Requirements

### Python
- Python **3.9+** recommended

### System
- NVIDIA GPU (optional but recommended)
- CUDA 12.x (for GPU acceleration)

---

## ğŸ“¦ Installation

```bash
pip install flask flask-cors llama-cpp-python pyngrok huggingface_hub
```

For GPU support (CUDA 12.1):
```bash
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```
---

## â–¶ï¸ Running the Application

```bash
python app.py
```

Once started, you will see:
- Local URL: `http://127.0.0.1:5000`
- Public Ngrok URL (printed in terminal)

---

## ğŸ§ª API Endpoints

| Endpoint | Method | Description |
|--------|-------|-------------|
| `/` | GET | Web UI |
| `/chat` | POST | Non-streaming chat |
| `/chat_stream` | POST | Streaming chat |
| `/reset` | POST | Reset conversation |
| `/debug` | GET | Debug info |
| `/test_format` | GET | Test response format |

---

## ğŸ“Œ Response Format

Every response strictly follows:

```
ğŸŒ¾ **Main Answer**

ğŸ“‹ **Key Points:**
â€¢ Point 1
â€¢ Point 2
â€¢ Point 3

ğŸ’¡ **Pro Tip:** Helpful farming advice
```

---
